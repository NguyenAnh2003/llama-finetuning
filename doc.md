# Introduction
1. LLM ranging from 7B to 65B parameters.
2. Trained on unlabeled datasets
3. Auto regressive model

# Target
Elementary Maths Solving

# Keywords
PEFT: traditional fine-tuning requires updating all of the model's params, which is expensive
    This work only updating a small subset of the model's parameters

# Libs
LoRA: https://www.youtube.com/watch?v=t509sv5MT0w
QLoRA

# External guides
https://www.youtube.com/watch?v=Us5ZFp16PaU

# References
https://github.com/VietnamAIHub/Vietnamese_LLMs
https://www.datacamp.com/tutorial/fine-tuning-llama-2
https://paperswithcode.com/paper/lora-low-rank-adaptation-of-large-language
https://viblo.asia/p/fine-tuning-mot-cach-hieu-qua-va-than-thien-voi-phan-cung-adapters-va-lora-5pPLkj3eJRZ